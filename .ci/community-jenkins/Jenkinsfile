// -*- groovy -*-
//
// Build an Open MPI Pull Request
//
//
// WORKSPACE Layout:
//   autotools-install/    Autotools install for the builder
//   ompi/                 Open MPI source tree

// We if we push changes to a PR, we don't need to keep old jobs running, so
// we'll use the milestone step in Jenkins. Using an example from
// https://stackoverflow.com/questions/40760716/jenkins-abort-running-build-if-new-one-is-started:
//
// - Build 1 runs and creates milestone 1.
// - While build 1 is running, build 2 fires. It has milestone 1 and milestone
//   2. It passes milestone 1, which causes build 1 to abort.
def buildNumber = env.BUILD_NUMBER as int
if (buildNumber > 1) {
    milestone(buildNumber - 1)
}
milestone(buildNumber)


node('linux') {
    stage('Initialize') {
	check_stages = prepare_check_stages()
	println("Initialized pipeline.")
    }

    // Today, we only expect to have one stage (do everything), but allow that we
    // may split build and test stages in the future.
    for (check_stage in check_stages) {
	parallel(check_stage)
    }

    stage('Finish') {
	println('Tests Completed')
    }
}

// TODO: add comment / fix label issue
// Checks if a given label is online. If it is, do nothing and return so the
// node can continue. If the platform is offline, throw and error to abort.
// def check_label_is_online(label) {
//     for (computer in computers) {
// 	if (computer.isOnline()) {
// 	    labelStr = computer.node.getLabelString()
// 	}
// 	if (labelStr == platform) {
// 	    return
// 	}
//     }
//     error "Aborting. ${label} is not online."
// }

// returns a list of build stages ("build Open MPI", "Build Tests", etc.),
// although currently we only support the one stage of "everything", where each
// build stage is a map of different configurations to test.
def prepare_check_stages() {
    // TODO: removed clang39, do we want to reevaluate which compilers to use
    // here? clang39 is old.
    def compilers = ["gcc5", "gcc6"]
    def platforms = ["amazon_linux_2", "rhel7", "rhel8", "ubuntu_18.04", "ubuntu_20.04"]
    def check_stages_list = []

    // build everything stage
    def build_parallel_map = [:]
    for (platform in platforms) {
	//check_label_is_online(platform)
	def name = "Platform: ${platform}".replaceAll("-", "")
	build_parallel_map.put(name, prepare_build(name, platform, ""))
    }

    for (compiler in compilers) {
	//check_label_is_online(compiler)
	def name = "Compiler: ${compiler}".replaceAll("-", "")
	build_parallel_map.put(name, prepare_build(name, compiler, "--compiler \"${compiler}\""))
    }

    build_parallel_map.put("32-bit", prepare_build("32-bit", "32bit_builds", "--32bit-build"))
    build_parallel_map.put("distcheck", prepare_build("distcheck", "rhel8", "--distcheck"))

    check_stages_list.add(build_parallel_map)

    return check_stages_list
}

def prepare_build(build_name, label, build_arg) {
    return {
	stage("${build_name}") {
	    node(label) {
		// So this part is to make sure that the Autotools specified in
		// the make_dist_tarball file of the branch are the ones we use
		// to build OMPI. The autotools-build.sh script (which is also
		// used in the dist tarball building) does some magic to pull
		// results from S3 if already available, and to cache between
		// jobs if builders are either not EC2 instances or are
		// reused. We can use the form "A+B=C", which, when used with
		// withEnv(), will prepend the value C to the environment
		// variable A.
		def build_env = ['PATH+AUTOTOOLS=$WORKSPACE/autotools-install/bin',
                                 'LD_LIBRARY_PATH+AUTOTOOLS=$WORKSPACE/autotools-install/lib']

		// TODO: if we uncomment this, it tries to make a env variable
		// like "--compiler...", which is illegal If build_arg is an
		// empty string, withEnv() will throw an error. So if build_arg
		// is empty, we don't need to append it.

		//if (build_arg.length() > 0) {
		//     build_env << build_arg
		//}
		checkout_code()
		dir("ompi") {
		    withEnv(build_env) {
			if (build_arg == "--distcheck") {
			    def autotools_build_root = "${WORKSPACE}/autotools-install"
			    def autotools_install_tree = "${autotools_build_root}/install"
			    sh "/bin/bash -x .ci/community-jenkins/autotools-build.sh -r ${autotools_build_root} -t ${autotools_install_tree} -z ./contrib/dist/make_dist_tarball ompi"
			}
			sh "/bin/bash -x .ci/community-jenkins/pr-builder.sh ${build_arg} ompi"
		    }
		}
	    }
	}
    }
}

def checkout_code() {
    checkout(changelog: false, poll: false,
	     scm: [$class: 'GitSCM', branches: [[name: '${CHANGE_BRANCH}']],
		   doGenerateSubmoduleConfigurations: false,
		   extensions: [[$class: 'SubmoduleOption',
				 disableSubmodules: false,
				 parentCredentials: true,
				 recursiveSubmodules: true,
				 reference: '',
				 trackingSubmodules: false],
				[$class: 'WipeWorkspace'],
				[$class: 'RelativeTargetDirectory',
				 relativeTargetDir: 'ompi']],
		   submoduleCfg: [], // FIXME: make this be the right repo/credentials
		   userRemoteConfigs: [[credentialsId: '685fec23-8b63-482f-9460-cea10efa585a',
					url: 'https://github.com/Joe-Downs/ompi/']]])
}
